predict(fit2,newdata=ndata2)
fit2=lm(mpg~wt+hp,data=mtcars)
summary(fit2)
?predict
df =  read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
## view the first few rows of the data
head(df)
sum(is.na(df))
## two-way contingency table of categorical outcome and predictors we want to make sure there are no empty cells
xtabs(~admit + rank, data = df)
#convert rank into factors
df$rank = factor(df$rank)
fit3 = glm(admit ~ gre + gpa + rank, data=df,family="binomial")
summary(fit3)
#predict probabilities of original values
(prob=predict(fit3,type=c("response")))
cbind(df, prob)
#another set of data for prediction
range(df$gre); range(df$gpa);levels(df$rank)
(newdata2 = data.frame(gre = c(200, 300, 400, 500), gpa = c(2.5, 3, 3.3, 3.75), rank = factor(c(1,2,3,4))))
str(newdata2)
newdata2b = cbind(newdata2, predictProb2=predict(fit3, newdata = newdata2, type = "response"))
newdata2b
summary(fit2)
source('~/rWork/rProjects/Analytics/Logistic Regression.R', echo=TRUE)
source('~/rWork/rProjects/Analytics/Logistic Regression.R', echo=TRUE)
install.packages("arules")
install.packages("arulesViz")
library(arules)  #install first
library(arulesViz) #install first
library(datasets)  # no need to install, just load it reqd for Groceries
data('Groceries')
Groceries
install.packages("forecast")
library(arules)  #install first
library(arulesViz) #install first
library(datasets)  # no need to install, just load it reqd for Groceries
data('Groceries')
Groceries
View(Groceries)
install.packages("zoo")
install.packages("timeSeries")
Groceries
#Structure of Groceries
str(Groceries)
inspect(Groceries[1:5])  #view
#Find Frequent Itemset
frequentItems = eclat (Groceries, parameter = list(supp = 0.01, minlen= 2, maxlen = 5))
#Find Frequent Itemset
frequentItems=eclat(Groceries)
inspect(frequ)
inspect(frequentItems)
frequentItems = eclat (Groceries, parameter = list(supp = 0.01, minlen= 2, maxlen = 5))
frequentItems
inspect(frequentItems[10:100])
frequentItems = eclat (Groceries, parameter = list(supp = 0.01, minlen= 3, maxlen = 5))
inspect(frequentItems)
frequentItems
inspect(frequentItems[10:100])
inspect(frequentItems[10:100])
inspect(frequentItems[1:100])
inspect(frequentItems[1:10])
inspect(frequentItems[10:10])
inspect(frequentItems[1:10])
inspect(frequentItems[1:20])
inspect(frequentItems[1:30])
frequentItems
inspect(frequentItems[1:32])
inspect(frequentItems[1:33])
inspect(frequentItems[1:32])
frequentItems = eclat (Groceries, parameter = list(supp = 0.1, minlen= 3, maxlen = 5))
frequentItems
frequentItems = eclat (Groceries, parameter = list(supp = 0.001, minlen= 3, maxlen = 5))
frequentItems
inspect(frequentItems[1:32])
frequentItems = eclat (Groceries, parameter = list(supp = 0.01, minlen= 3, maxlen = 5))
frequentItems
inspect(frequentItems[1:32])
#inspect(frequentItems[100:122])
#Descending Sort frequent items by count : 1 to 25 itemsets
inspect(sort (frequentItems, by="count", decreasing=TRUE)[1:25])
#inspect(frequentItems[100:122])
#Descending Sort frequent items by count : 1 to 25 itemsets
inspect(sort (frequentItems, by="count", decreasing=TRUE)[1:32])
#Support is : support(A&B) = n(A&B)/ N
#Plot the Frequency Plot
itemFrequencyPlot(Groceries,topN = 15,type="absolute")
itemFrequencyPlot(Groceries, topN = 10, type='relative')
abline(h=0.2)
# Create rules and the relationship between items
#parameters are min filter conditions
rules = apriori(Groceries, parameter = list(supp = 0.005, conf = 0.5, minlen=2))
inspect (rules[1:5])
#Sort Rules by confidence, lift and see the data
rulesc <- sort (rules, by="confidence", decreasing=TRUE)
inspect(rulesc[1:5])
rulesl <- sort (rules, by="lift", decreasing=TRUE)
inspect (rulesl[1:5])
#How To Control The Number Of Rules in Output ?
#maxlen, minlen, supp, conf
rules2 = apriori (Groceries, parameter = list (supp = 0.001, conf = 0.5, minlen=2, maxlen=3))
inspect(rules2[1:5])
#Find what factors influenced an event ‘X’
rules3 = apriori (data=Groceries, parameter=list (supp=0.002,conf = 0.8), appearance = list (default="lhs",rhs="whole milk"), control = list (verbose=F))
inspect(rules3[1:5])
inspect(rules3)
sum(is.redundant(rules2))
(redundant = which(is.redundant(rules2)))
#inspect(subset(rules2, subset=lhs %ain% c('citrus fruit','rice') & rhs %in% 'whole milk' ))
#remove it
rulesNR = rules2[-redundant]
is.redundant(rulesNR)
sum(is.redundant(rulesNR))  #ok now
#Find out what events were influenced by a given event
subset1 = subset(rules2, appearance = list (default="lhs",rhs="whole milk"))
subset1 = subset(rules2, subset=rhs %in% 'bottled beer' )
inspect(subset1)
inspect(rules2)
subset1 = subset(rules2, subset=rhs %in% 'bottled beer' )
inspect(subset1)
#Find out what events were influenced by a given event
subset1 = subset(rules2, appearance = list (default="lhs",rhs="whole milk"))
inspect(subset1)
#Visualizing The Rules -----
plot(subset1[1:10])
#Visualizing The Rules -----
plot(subset1[1:20])
#Visualizing The Rules -----
plot(subset1[1:10])
subset1 = subset(rules2, subset=rhs %in% 'bottled beer' )
inspect(subset1)
#Visualizing The Rules -----
plot(subset1[2:10])
#Visualizing The Rules -----
plot(subset1[1:10])
#libraries
library(arules)
library(arulesViz)
#Method3 Use: ----
#Data in the form of list
itemlist = list(c('I1','I2','I5'), c('I2','I4'), c('I2','I3'),c('I1','I2','I4'),c('I1','I3'),c('I2','I3'),c('I1','I3'),c('I1','I2','I3','I5'),c('I1','I2','I3'))
itemlist
length(itemlist)
## set transaction names
names(itemlist) <- paste("Tr",c(1:9), sep = "")
itemlist
## coerce into transactions
tdata3 <- as(itemlist, "transactions")
tdata3
summary(tdata3)
tdata=tdata3
#Data ready - Perform AR ----
## analyze transactions
summary(tdata)
itemlist
image(tdata)
#Analysis
freqitems = eclat(tdata) #default support=.1
freqitems = eclat(tdata, parameter = list(minlen=1, supp=.1, maxlen=2 ))
freqitems
inspect(freqitems)
freqitems
image(tdata)
support(items(freqitems[1:2]), transactions=tdata)
inspect(freqitems[1])
inspect(items(freqitems[1]))
itemFrequencyPlot(tdata,topN = 5,type="absolute")
itemFrequencyPlot(tdata,topN = 5,type="relative", horiz=T)
write.csv(as.data.frame(inspect(freqitems)),'freqitems1.csv') #To save the computed data into a file
freqitems = eclat(tdata, parameter = list(minlen=1, supp=.1, maxlen=2 ))#Selective searching
inspect(freqitems)
itemlist
length(itemlist)
freqitems = eclat(tdata, parameter = list(minlen=1, supp=.2, maxlen=2 ))#Selective searching
inspect(freqitems)
freqitems = eclat(tdata, parameter = list(minlen=1, supp=.1, maxlen=2 ))#Selective searching
inspect(freqitems)
freqitems = eclat(tdata, parameter = list(minlen=1, supp=.01, maxlen=2 ))#Selective searching
inspect(freqitems)
freqitems = eclat(tdata, parameter = list(minlen=1, supp=.1, maxlen=2 ))#Selective searching
inspect(freqitems)
install.packages("quantmod")
library(quantmod)
getSymbols("HDFCBANK.BO", src="yahoo")
HDFCBANK.BO
tail(HDFCBANK.BO)
#library(quantmod)
getSymbols("^BSESN",src="yahoo" , from ="2016-10-23", to = Sys.Date())
View(BSESN)
chart_Series(BSESN)
getSymbols("GS") #Goldman OHLC from yahoo
#[1] "GS"
is.OHLC(GS) # does the data contain at least OHL and C?
has.Vo(GS) # how about volume?
Op(GS) # just the Open column please.
seriesHi(GS) # where and what was the high point
range(GS)
range(GS$GS.Open)
head(GS)
tail(GS)
OpCl(GS) #daily percent change open to close
OpOp(GS) #one period open to open change
HiCl(GS) #the percent change from high to close
head(GS)
head(HiCl(GS))
Lag(Cl(GS)) #One period lag of the close
head(GS)
head(Lag(Cl(GS)))
Lag(Cl(GS),c(1,3,5)) #One, three, and five period lags
Next(OpCl(GS)) #The next periods open to close - today!
head(Next(OpCl(GS)))
head(GS)
# Open to close one-day, two-day and three-day lags
Delt(Op(GS),Cl(GS),k=1:3)
GS['2007'] #returns all Goldman's 2007 OHLC
GS['2018'] #now just 2018
GS['2018-08'] #now just January of 2018
first(GS)
last(GS) #returns the last obs.
last(GS,8) #returns the last 8 obs.
# let's try something a bit cooler.
last(GS, '3 weeks')
last(GS, '-3 weeks') # all except the last 3 weeks
last(GS, '3 months')
#from first 2 weeks, last 3 days
first(GS, '2 weeks')
last(first(GS, '2 weeks'), '3 days')
#date in yyyy-mm-dd
dates1a = c('2018-21-4', '2018-29-4')
class(dates1a)
?as.Date
dates1b
as.Date(dates1a)  # error
dates1a
dates1b = as.Date(dates1a, format='%Y-%d-%m')
class(dates1b)
dates1b
dates1b + 1
as.Date('2018-04-29') + 1
#default format %Y-%m-%d
dates2a = c('2018-4-21')
class(dates2a)  # character so far
(dates2b = as.Date(dates2a))  # convert to date
class(dates2b)  # date now
format(dates2b, format=('%d-%m-%Y')) # print in different format
format(dates2b, format=('%d / %B - %Y')) # print in different format
dates2b
as.Date('2018-04-29') + seq('1:10)
#default format %Y-%m-%d
dates2a = c('2018-4-21')
format(dates2b, format="%A  %d  %m  %y") # another format
pumba = c('09-07-1993', '08-08-1994', '04-11-1994')
#default format %Y-%m-%d
dates2a = c('2000-07-23')
class(dates2a)  # character so far
(dates2b = as.Date(dates2a))  # convert to date
class(dates2b)  # date now
format(dates2b, format=('%d-%m-%Y')) # print in different format
format(dates2b, format=('%d / %B - %Y')) # print in different format
format(dates2b, format="%A  %d  %m  %y") # another format
class(pumba)
pumba1 = as.Date(pumba, '%d-%m-%Y')
format(pumba1, '%A')
format(as.Date('18-04-1994', '%d-%m-%Y'), '%A')
#System Date
Sys.Date()
format(Sys.Date(), format="%A: %d %B")
#increment/ decrement dates
dates2b
(course = dates2b + 0:11) # start : 11 days course
cat(format(course, format="%B-%d"))
months(course)
weekdays(course)
quarters(course)
paste(quarters(course),'2018',sep='-')
#one more practise on date format
dates3a =as.Date('30Apr18',format("%d%b%y"))
class(dates3a)
#Difference in dates
course
min(course)  # first date
max(course)  # last date
range(course) # start to end
mean(course)  # avg date ?
median(course) # middle date
course
course[c(1,5)] # 1st & 5th date
course[1] ; course[9]
(duration = course[8] - course[1])
(duration = max(course) - min(course))
#Date of Birth
dob = as.Date('14-08-1994', '%d-%m-%Y')
dob
dob1= dob + seq(1,1000,30)  # create 1000 dates
length(dob1)
as.numeric((Sys.Date() - dob)/365)  #: Years
#par(mfrow=c(1,1))
boxplot(as.numeric((Sys.Date() - dob1)/365))# : Years
as.numeric((Sys.Date() - dob1)/365)# : Years
mean(as.numeric((Sys.Date() - dob1)/365))# : Years
(duration2 = max(course) - min(course))
#Sequence of Dates----
seq(1,10,2)
#by years : from start date to end date
seq(as.Date("2016/1/1"), as.Date("2018/5/1"), "years")
seq(as.Date("2016/1/1"), as.Date("2018/5/1"), "months")
seq(as.Date("2017/1/1"), by = "days", length.out = 6)
(students = c('ashish','chirag'))
## by month : 6 months
seq(as.Date("2017/1/1"), by = "month", length.out = 6)
seq(as.Date("2017/1/1"), by = "month", along.with = c(3,2,43,5,6,7))  #
seq(as.Date("2017/1/1"), by = "month", along.with = students)  #
seq(as.Date("2017/1/1"), by = "quarter", along.with = students)  #
seq(as.Date("2017/1/1"), by = "month", length.out = length(c(3,2,43)))
#Find 7th of all months between two dates
(dateseqF = seq(as.Date("2017/1/7"), as.Date("2018/1/7"), by = "1 month"))  # order
#Find 7th of all months between two dates
(dateseqF = seq(as.Date("2017/1/7"), as.Date("2018/1/7"), by = "1 month"))  # order
# dates in opposite order
(dateseq = seq(as.Date("2018/1/7"), as.Date("2017/1/7"), by = "-2 month"))  # reverse order
# then reverse them
rev(dateseq)# correct the order
format(rev(dateseq), "%A : %d-%b")
## quarters
seq(as.Date("2017/1/1"), as.Date("2018/1/1"), by = "quarter")
#Find 7th of all months between two dates
(dateseqF = seq(as.Date("2017/1/7"), as.Date("2018/1/7"), by = "1 month"))  # order
# dates in opposite order
(dateseq = seq(as.Date("2018/1/7"), as.Date("2017/1/7"), by = "-2 month"))  # reverse order
# then reverse them
rev(dateseq)# correct the order
format(rev(dateseq), "%A : %d-%b")
#another Sequence : using another package
chron::seq.dates("01/01/2017", "12/31/2017", by = "months")
install.packages("chron")
install.packages("lubridate")
#Eg1
library(lubridate)
lubridate::ymd("20110604")
lubridate::mdy("06-04-2011")
lubridate::dmy("04/06/2011")
#Eg1
#If your date includes time information, add h, m, and/or s to the name of the function. ymd_hms() is probably the most common date time format. To read the dates in with a certain time zone, supply the official name of that time zone in the tz argument.
OlsonNames()
Sys.timezone()
Sys.timezone(location=F)
arrive <- ymd_hms("2018-04-27 18:40:15", tz = "Asia/Calcutta")
Sys.timezone()
arrive
leave <- ymd_hms("2018-04-29 22:00:00", tz = "Asia/Calcutta")
leave
#Eg
second(arrive)
second(arrive) = 25  #change
second(arrive)
arrive
minute(arrive)
hour(arrive)
day(arrive)
wday(arrive)
# Create Time Series data of Finance Sales
sales = c(18, 33, 41, 7, 34, 35, 24, 25, 24, 21, 25, 20,
22, 31, 40, 29, 25, 21, 22, 54, 31, 25, 26, 35)
length(sales)
sales ; class(sales)  # vector of sales values
#put in TS without any dates : format of TS
?ts  # help
#ts(data = NA, start = 1, end = numeric(), frequency = 1)
#start - time of 1st obsv - single no / vector of 2 integers
#frequency - no of obvsv per unit of time
#No of obsv per unit time
(tsales2a = ts(sales, start=1, end=12)) #only first 12 considered
(ts(sales, start=1, end=12, freq=1)) #only first 12 considered
(ts(sales, start=1, end=12, freq=2)) #
(ts(sales, start=1, end=12, freq=3)) #
(ts(sales, start=1, end=12, freq=4)) # Qtrly series
(ts(sales, start=1, end=12, freq=5)) #
(ts(sales, start=1, end=12, freq=6)) #
(ts(sales, start=1, end=12, freq=12)) #  12 months * 12 years
#Specify data periods in start and end
#specify only start dates & freq
(tsales3a = ts(sales, start=c(2017, 1), frequency=12)) # years 2017 to 2018, 24 values, monthwise 24 observations spread to 2 years
sales2=c(sales,sales)
length(sales2)
ts(sales, start=c(2017, 4), end=c(2018,3), frequency=12)
ts(sales, start=c(2017, 2), frequency=12)  # different start month
ts(sales, start=c(2017, 2), frequency=4)  # different start month
plot(ts(sales, start=c(2017,1), frequency=1))  # different start month
#Specify start and end date periods
(tsales3b = ts(sales, start=c(2016,4), end=12) ) #error start and end to be of same format
(tsales3b = ts(sales, start=c(2016), end=c(2018))) # default freq=1 once a year 1st 3 values becomes year sales value
# Daily Sales Data
sales2 = ceiling(runif(365, 50,100))
sales2
sales2
(dailyTSdata = ts(sales2, start=c(2017,1), frequency=365))
plot(dailyTSdata)
start(dailyTSdata)
end(dailyTSdata)
#Weekly Sales Data  52 weeks in a year
sales3 = ceiling(runif(52, 50,100))
(weeklyTSdata = ts(sales3, start=c(2017,3), frequency=52))
weeklyTSdata
plot(weeklyTSdata)
#Yearly Sales Data : 2000 to 2017
seq(1,10,2)
seq(1,20, along.with = c(1:5))
seq(1,20, along.with = sales)  # 24 values
(values= trunc(seq(1,20, along.with = c(2000:2017))))  # take length from 2000 to 2017
(sales4 = floor(rnorm(values, mean=50, sd=10)) ) #pick up length from values
(yearlyTSdata = ts(sales4, start=c(2000), end=c(2017)))
plot(yearlyTSdata)
start(yearlyTSdata); end(yearlyTSdata) ;frequency(yearlyTSdata)
#diff and lag & window in ts
tsales3c
(values= trunc(seq(1,20, along.with = c(2000:2017))))  # take length from 2000 to 2017
(sales4 = floor(rnorm(values, mean=50, sd=10)) ) #pick up length from values
(yearlyTSdata = ts(sales4, start=c(2000), end=c(2017)))
plot(yearlyTSdata)
start(yearlyTSdata); end(yearlyTSdata) ;frequency(yearlyTSdata)
#diff and lag & window in ts
tsales3c
(tsales3c = ts(sales, start=c(2016,4), end=c(2018,4), frequency=12)) # period diveded into 24 equal intervals
tsales3c
plot(tsales3c)
#diff and lag & window in ts
tsales3c
tsales = tsales3c
tsales
range(tsales)
diff(tsales)
diff(tsales,lag=1)
diff(tsales,lag=2)
diff(tsales,lag=6)
cycle(tsales)
tsales
tsales
#subset Time Series with range of dates
(tsales.subset = window(tsales, start=c(2003, 5), end=c(2004, 6))) #error due to range period incorrect
tsales
(tsales.subset = window(tsales, start=c(2016, 5), end=c(2017, 8)))
data(AirPassengers)
class(AirPassengers)
#This tells you that the data series is in a time series format
str(AirPassengers)
head(AirPassengers); tail(AirPassengers)
start(AirPassengers)
#This is the start of the time series
end(AirPassengers)
#[1] 1960 12
#This is the end of the time series
frequency(AirPassengers)  # $[1] 12
#The cycle of this time series is 12months in a year
summary(AirPassengers)
#The number of passengers are distributed across the spectrum
plot(AirPassengers)
#This will plot the time series
abline(reg=lm(AirPassengers~time(AirPassengers)))
cycle(AirPassengers)
#This will print the cycle across years.
plot(aggregate(AirPassengers,FUN=mean))
#This will aggregate the cycles and display a year on year trend
boxplot(AirPassengers~cycle(AirPassengers))
plot(aggregate(AirPassengers,FUN=mean))
plot(log(AirPassengers))
abline(reg=lm(log(AirPassengers) ~ time(AirPassengers)))
plot(diff (log(AirPassengers)))
abline(h=0, col='red')
abline(reg=lm(diff(log(AirPassengers)) ~ time(AirPassengers)))
#Model
acf(AirPassengers)
acf(diff (log(AirPassengers)))
pacf(diff (log(AirPassengers)))
fit = arima(log(AirPassengers), c(0,1,1), seasonal =
list(order = c(0,1,1), period = 12) )
pred = predict(fit, n.ahead = 10 * 12)
pred1 = 2.718 * pred$pred
ts.plot(AirPassengers, pred1, log='y', lty=c(1,3))
?arima
#https://rpubs.com/emb90/137525
# Data Set - AirPassengers
x=c(9.23221232,5.3430000)
x
options(digits=2)
x
?AirPassengers
head(AirPassengers)
AirPassengers
str(AirPassengers)
class(AirPassengers)
#stl(x, s.window, t.window = ) # command to do decomp
stl(AirPassengers, s.window = 'periodic') # seasons to be considered periodic ie not changing over time
plot(AirPassengers) # Pattern of data : see increasing seasonal values suggesting multiplicative Model
stl1 = stl(AirPassengers, s.window = 'periodic')
plot(stl1) # actual data, seasonal, long term trends, remainder/ irregular
class(stl1)
stl1$time.series
?arima
par(mfrow=c(1,2)) #1 row 2column disply
hist(mtcars$mpg)
hist(mtcars$wt)
par(mfrow=c(2,1))
hist(mtcars$mpg)
hist(mtcars$wt)
par(mfrow=c(2,2))
hist(mtcars$mpg)
hist(mtcars$wt)
pie(table(mtcars$cly))
?txn_data
?list
t=c(5,10,15,5,15)
mean(t)
